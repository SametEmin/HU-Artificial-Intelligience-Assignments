{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b1f085",
   "metadata": {},
   "source": [
    "ASSIGNMENT-5 \n",
    "Samet Emin Özen\n",
    "2220765018\n",
    "\n",
    "In this code we will make precision about person's personality.\n",
    "lets start with importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811d87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a261a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    distances = np.sqrt(np.sum((X_train - x) ** 2, axis=1))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d3fb4c",
   "metadata": {},
   "source": [
    "this function create distances list and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ee863df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def KNN(k):\n",
    "    global X_train,dataset\n",
    "    dataset=pd.read_csv(r\"C:\\Users\\OEM\\Desktop\\Assignment5\\data.csv\", encoding = \"ISO-8859-1\") \n",
    "    dataset=dataset.drop(\"Response Id\",axis=1)             \n",
    "    dataset=dataset.replace({\"Personality\":{\"ESTJ\":0,\"ENTJ\":1,\"ESFJ\":2,\"ENFJ\":3,\"ISTJ\":4,\"ISFJ\":5,\"INTJ\":6,\"INFJ\":7,\"ESTP\":8,\n",
    "                                    \"ESFP\":9,\"ENTP\":10,\"ENFP\":11,\"ISTP\":12,\"ISFP\":13,\"INTP\":14,\"INFP\":15} })   \n",
    "    data_np=dataset.to_numpy()\n",
    "    \n",
    "    #I am preparing dataframe here\n",
    "    \n",
    "    \n",
    "    X= data_np[:,:-1]\n",
    "    Y= data_np[:,-1]\n",
    "    \n",
    "    for k in [1,3,5,7,9]:\n",
    "        for f in range(5):# this work for cross validation\n",
    "            X_test=X[int(f*(len(X)-1)*0.20):int((f+1)*(len(X)-1)*0.20),:]\n",
    "            X_train=np.vstack((X[0:int(f*(len(X)-1)*0.20),:],X[int((f+1)*(len(X)-1)*0.20):,:]))\n",
    "            Y_test=Y[int(f*(len(Y)-1)*0.20):int((f+1)*(len(Y)-1)*0.20)]\n",
    "            Y_train=np.concatenate((Y[0:int(f*(len(Y)-1)*0.20)],Y[int((f+1)*(len(Y)-1)*0.20):]))\n",
    "\n",
    "\n",
    "            #probability lists \n",
    "            acc_list=[]\n",
    "            acc=[]\n",
    "            pre=[]\n",
    "            rec=[]\n",
    "            # confusion matrix\n",
    "            cm=np.zeros(16*16).reshape(16,16)\n",
    "\n",
    "            # the most important part is here \n",
    "            for i in range(len(X_test)):\n",
    "                dict_ex={}\n",
    "                number=dataset.iloc[np.argsort(predict(X_test[i]))[:k]][\"Personality\"].to_numpy()\n",
    "\n",
    "\n",
    "                result=max(set(number),key=list(number).count  )  # prediction personality encode    \n",
    "\n",
    "                if result==Y_test[i]:\n",
    "                    acc_list.append(True)\n",
    "                    cm[result,result]+=1\n",
    "                else:\n",
    "                    acc_list.append(False)\n",
    "                    cm[Y_test[i],result]+=1\n",
    "\n",
    "                print(\"Progress:%{} loop{}\".format(i*100//len(X_test),f),end=\"\\r\")\n",
    "\n",
    "\n",
    "                acc.append((acc_list.count(True)/len(acc_list)))\n",
    "\n",
    "                rec.append(cm[Y_test[i],Y_test[i]]/int(np.sum(cm[:,Y_test[i]])))\n",
    "\n",
    "                pre.append(cm[Y_test[i],Y_test[i]]/int(np.sum(cm[Y_test[i],:])))\n",
    "\n",
    "        print(\"k: {} Accuracy %\".format(k),sum(acc)/len(acc)*100)\n",
    "        print(\"k: {} Precision %\".format(k),sum(pre)/len(pre)*100)\n",
    "        print(\"k: {} Recall %\".format(k),sum(rec)/len(rec)*100)\n",
    "        print(cm)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "     \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "75257e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1 Accuracy % 97.90156479357864\n",
      "k: 1 Precision % 97.8931223513101\n",
      "k: 1 Recall % 97.9060387084232\n",
      "[[739.   1.   2.   1.   1.   2.   0.   0.   0.   0.   0.   2.   0.   1.\n",
      "    1.   2.]\n",
      " [  0. 719.   1.   1.   0.   0.   0.   2.   1.   2.   0.   0.   0.   1.\n",
      "    2.   2.]\n",
      " [  0.   1. 735.   1.   0.   1.   1.   0.   2.   2.   1.   3.   3.   1.\n",
      "    4.   1.]\n",
      " [  0.   1.   1. 722.   0.   0.   1.   1.   0.   1.   1.   2.   1.   4.\n",
      "    2.   1.]\n",
      " [  2.   1.   0.   0. 736.   0.   0.   0.   0.   1.   1.   4.   1.   1.\n",
      "    4.   1.]\n",
      " [  0.   0.   1.   3.   1. 727.   4.   0.   4.   0.   0.   0.   2.   1.\n",
      "    3.   1.]\n",
      " [  0.   0.   4.   0.   1.   1. 694.   2.   2.   1.   1.   3.   3.   0.\n",
      "    1.   1.]\n",
      " [  0.   1.   1.   0.   0.   1.   1. 726.   1.   2.   0.   2.   0.   2.\n",
      "    4.   1.]\n",
      " [  2.   2.   1.   0.   0.   2.   2.   0. 756.   1.   0.   0.   2.   1.\n",
      "    1.   0.]\n",
      " [  0.   2.   1.   0.   0.   3.   0.   1.   1. 749.   2.   0.   0.   1.\n",
      "    2.   0.]\n",
      " [  2.   1.   0.   1.   0.   1.   2.   1.   0.   0. 749.   0.   1.   2.\n",
      "    1.   5.]\n",
      " [  2.   0.   0.   1.   0.   1.   2.   0.   0.   2.   1. 756.   0.   2.\n",
      "    1.   0.]\n",
      " [  0.   1.   1.   2.   1.   2.   2.   0.   1.   0.   0.   0. 747.   2.\n",
      "    0.   0.]\n",
      " [  1.   6.   0.   3.   0.   0.   3.   0.   0.   2.   0.   3.   0. 720.\n",
      "    1.   3.]\n",
      " [  0.   2.   1.   3.   2.   1.   1.   2.   0.   1.   1.   2.   0.   4.\n",
      "  715.   1.]\n",
      " [  1.   2.   0.   1.   6.   0.   4.   1.   2.   1.   3.   0.   0.   1.\n",
      "    0. 743.]]\n",
      "k: 3 Accuracy % 99.02388451916025\n",
      "k: 3 Precision % 99.02642926546716\n",
      "k: 3 Recall % 99.0288159068581\n",
      "[[743.   1.   2.   1.   0.   1.   0.   0.   0.   0.   0.   1.   0.   1.\n",
      "    1.   1.]\n",
      " [  0. 722.   1.   1.   0.   0.   0.   1.   1.   2.   0.   0.   0.   1.\n",
      "    1.   1.]\n",
      " [  0.   1. 742.   1.   1.   0.   1.   0.   1.   2.   1.   2.   0.   1.\n",
      "    3.   0.]\n",
      " [  0.   0.   1. 725.   0.   1.   1.   1.   0.   1.   1.   0.   1.   3.\n",
      "    2.   1.]\n",
      " [  1.   1.   0.   0. 745.   0.   0.   0.   0.   0.   0.   3.   0.   1.\n",
      "    0.   1.]\n",
      " [  1.   0.   1.   2.   1. 736.   2.   0.   1.   0.   0.   0.   1.   0.\n",
      "    1.   1.]\n",
      " [  0.   0.   1.   0.   0.   0. 707.   2.   1.   0.   1.   0.   1.   0.\n",
      "    0.   1.]\n",
      " [  0.   0.   1.   0.   1.   1.   1. 728.   0.   2.   0.   1.   0.   1.\n",
      "    5.   1.]\n",
      " [  0.   2.   0.   0.   0.   0.   0.   0. 766.   1.   0.   0.   1.   0.\n",
      "    0.   0.]\n",
      " [  0.   1.   1.   0.   0.   2.   0.   1.   0. 753.   1.   0.   0.   1.\n",
      "    2.   0.]\n",
      " [  0.   1.   0.   0.   0.   0.   0.   1.   0.   0. 758.   0.   1.   2.\n",
      "    1.   2.]\n",
      " [  0.   0.   0.   1.   0.   1.   1.   0.   0.   0.   1. 762.   0.   2.\n",
      "    0.   0.]\n",
      " [  0.   1.   1.   1.   0.   0.   0.   0.   0.   0.   0.   0. 755.   1.\n",
      "    0.   0.]\n",
      " [  0.   1.   0.   1.   0.   0.   0.   0.   0.   1.   1.   1.   0. 733.\n",
      "    1.   3.]\n",
      " [  0.   1.   2.   2.   1.   1.   1.   0.   0.   1.   0.   1.   0.   1.\n",
      "  725.   0.]\n",
      " [  0.   2.   0.   1.   2.   0.   0.   0.   1.   1.   1.   0.   0.   0.\n",
      "    0. 757.]]\n",
      "k: 5 Accuracy % 99.06920490902043\n",
      "k: 5 Precision % 99.06849187691805\n",
      "k: 5 Recall % 99.07833084231406\n",
      "[[743.   1.   2.   1.   0.   1.   0.   0.   0.   0.   0.   1.   0.   1.\n",
      "    1.   1.]\n",
      " [  0. 722.   1.   1.   0.   0.   0.   1.   1.   2.   0.   0.   0.   1.\n",
      "    1.   1.]\n",
      " [  0.   1. 743.   1.   1.   0.   1.   0.   1.   2.   0.   2.   0.   1.\n",
      "    3.   0.]\n",
      " [  0.   0.   1. 726.   0.   0.   1.   1.   0.   1.   1.   0.   1.   3.\n",
      "    2.   1.]\n",
      " [  1.   1.   0.   0. 745.   0.   0.   0.   0.   0.   0.   3.   0.   1.\n",
      "    0.   1.]\n",
      " [  1.   0.   1.   2.   1. 737.   2.   0.   1.   0.   0.   0.   0.   0.\n",
      "    1.   1.]\n",
      " [  0.   0.   0.   0.   0.   0. 708.   2.   1.   0.   1.   0.   1.   0.\n",
      "    0.   1.]\n",
      " [  0.   0.   1.   0.   0.   1.   1. 729.   0.   2.   0.   1.   0.   1.\n",
      "    5.   1.]\n",
      " [  0.   2.   0.   0.   0.   0.   1.   0. 764.   1.   0.   0.   1.   0.\n",
      "    0.   1.]\n",
      " [  0.   1.   0.   0.   0.   2.   0.   1.   1. 753.   1.   0.   0.   1.\n",
      "    2.   0.]\n",
      " [  0.   1.   0.   0.   0.   0.   0.   1.   0.   0. 758.   0.   1.   2.\n",
      "    1.   2.]\n",
      " [  0.   0.   0.   1.   0.   1.   1.   0.   0.   0.   1. 762.   0.   2.\n",
      "    0.   0.]\n",
      " [  0.   1.   1.   1.   0.   0.   0.   0.   0.   0.   0.   0. 755.   1.\n",
      "    0.   0.]\n",
      " [  0.   0.   0.   1.   0.   0.   0.   0.   0.   1.   0.   1.   0. 736.\n",
      "    1.   2.]\n",
      " [  0.   1.   0.   2.   1.   1.   1.   0.   0.   1.   0.   0.   0.   1.\n",
      "  728.   0.]\n",
      " [  0.   2.   0.   1.   2.   0.   0.   0.   1.   1.   1.   0.   0.   0.\n",
      "    0. 757.]]\n",
      "k: 7 Accuracy % 99.07028347012759\n",
      "k: 7 Precision % 99.06894357418173\n",
      "k: 7 Recall % 99.078895259197\n",
      "[[743.   1.   2.   1.   0.   1.   0.   0.   0.   0.   0.   1.   0.   1.\n",
      "    1.   1.]\n",
      " [  0. 722.   1.   1.   0.   0.   0.   1.   1.   2.   0.   0.   0.   1.\n",
      "    1.   1.]\n",
      " [  0.   1. 743.   1.   1.   0.   1.   0.   1.   2.   0.   2.   0.   1.\n",
      "    3.   0.]\n",
      " [  0.   0.   1. 726.   0.   0.   1.   1.   0.   1.   1.   0.   1.   3.\n",
      "    2.   1.]\n",
      " [  1.   1.   0.   0. 744.   0.   0.   0.   1.   0.   0.   3.   0.   1.\n",
      "    0.   1.]\n",
      " [  1.   0.   1.   1.   1. 737.   2.   0.   1.   0.   0.   0.   0.   0.\n",
      "    1.   2.]\n",
      " [  0.   0.   1.   0.   0.   0. 707.   2.   1.   0.   1.   0.   1.   0.\n",
      "    0.   1.]\n",
      " [  0.   0.   1.   0.   0.   1.   1. 730.   0.   2.   0.   1.   0.   0.\n",
      "    5.   1.]\n",
      " [  0.   2.   0.   0.   0.   0.   0.   0. 766.   1.   0.   0.   1.   0.\n",
      "    0.   0.]\n",
      " [  0.   1.   0.   0.   0.   2.   0.   1.   1. 753.   1.   0.   0.   1.\n",
      "    2.   0.]\n",
      " [  0.   1.   0.   0.   0.   0.   0.   1.   0.   0. 758.   0.   1.   2.\n",
      "    1.   2.]\n",
      " [  0.   0.   0.   1.   0.   1.   1.   0.   0.   0.   1. 762.   0.   2.\n",
      "    0.   0.]\n",
      " [  0.   1.   1.   1.   0.   0.   0.   0.   0.   0.   0.   1. 754.   1.\n",
      "    0.   0.]\n",
      " [  0.   0.   0.   1.   0.   0.   0.   0.   0.   1.   0.   1.   0. 736.\n",
      "    1.   2.]\n",
      " [  0.   1.   0.   2.   1.   1.   1.   0.   0.   1.   0.   0.   0.   1.\n",
      "  728.   0.]\n",
      " [  0.   2.   0.   1.   2.   0.   0.   0.   1.   1.   1.   0.   0.   0.\n",
      "    0. 757.]]\n",
      "k: 9 Accuracy % 99.09340541289102\n",
      "k: 9 Precision % 99.09070159968982\n",
      "k: 9 Recall % 99.10266903017536\n",
      "[[743.   1.   2.   1.   0.   1.   0.   0.   0.   0.   0.   1.   0.   1.\n",
      "    1.   1.]\n",
      " [  0. 722.   1.   1.   0.   0.   0.   1.   1.   2.   0.   0.   0.   1.\n",
      "    1.   1.]\n",
      " [  0.   1. 743.   1.   1.   0.   1.   0.   1.   2.   0.   2.   0.   1.\n",
      "    3.   0.]\n",
      " [  0.   0.   1. 726.   0.   0.   1.   1.   0.   1.   1.   0.   1.   3.\n",
      "    2.   1.]\n",
      " [  1.   1.   0.   0. 744.   0.   0.   0.   1.   0.   0.   3.   0.   1.\n",
      "    0.   1.]\n",
      " [  1.   0.   1.   1.   1. 739.   1.   0.   1.   0.   0.   0.   0.   0.\n",
      "    1.   1.]\n",
      " [  0.   0.   0.   0.   0.   0. 708.   2.   1.   0.   1.   0.   1.   0.\n",
      "    0.   1.]\n",
      " [  0.   0.   1.   0.   0.   1.   1. 730.   0.   2.   0.   1.   0.   0.\n",
      "    5.   1.]\n",
      " [  0.   2.   0.   0.   0.   0.   0.   0. 766.   1.   0.   0.   1.   0.\n",
      "    0.   0.]\n",
      " [  0.   1.   0.   0.   0.   2.   0.   1.   1. 752.   1.   1.   0.   1.\n",
      "    2.   0.]\n",
      " [  0.   1.   0.   0.   0.   0.   0.   1.   0.   0. 758.   0.   1.   2.\n",
      "    1.   2.]\n",
      " [  0.   0.   0.   1.   0.   1.   1.   0.   0.   0.   1. 762.   0.   2.\n",
      "    0.   0.]\n",
      " [  0.   1.   1.   1.   0.   0.   0.   0.   0.   0.   0.   0. 755.   1.\n",
      "    0.   0.]\n",
      " [  0.   0.   0.   1.   0.   0.   0.   0.   0.   1.   0.   1.   0. 736.\n",
      "    1.   2.]\n",
      " [  0.   1.   0.   2.   1.   1.   1.   0.   0.   1.   0.   0.   0.   1.\n",
      "  728.   0.]\n",
      " [  0.   2.   0.   1.   2.   0.   0.   0.   1.   1.   1.   0.   0.   0.\n",
      "    0. 757.]]\n"
     ]
    }
   ],
   "source": [
    "KNN(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44519a8",
   "metadata": {},
   "source": [
    "In the above part I have predicted (for k=1,3,5,7,9 and without feat. norm.) with cross validation and printed the accuracy , precision , recall and sample confusion matrix.Then I am gonna do with feauture normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1d46ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_F_N():\n",
    "    global X_train,dataset\n",
    "    dataset=pd.read_csv(r\"C:\\Users\\OEM\\Desktop\\Assignment5\\data.csv\", encoding = \"ISO-8859-1\") \n",
    "    dataset=dataset.drop(\"Response Id\",axis=1)             \n",
    "    dataset=dataset.replace({\"Personality\":{\"ESTJ\":0,\"ENTJ\":1,\"ESFJ\":2,\"ENFJ\":3,\"ISTJ\":4,\"ISFJ\":5,\"INTJ\":6,\"INFJ\":7,\"ESTP\":8,\n",
    "                                    \"ESFP\":9,\"ENTP\":10,\"ENFP\":11,\"ISTP\":12,\"ISFP\":13,\"INTP\":14,\"INFP\":15} })   \n",
    "    \n",
    "    dataset.iloc[:,:-1]=(dataset.iloc[:,:-1]+3)/6  #NORMALİZATİON CODE\n",
    "\n",
    "    data_np=dataset.to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    X= data_np[:,:-1]\n",
    "    Y= data_np[:,-1]\n",
    "    \n",
    "    for k in [1,3,5,7,9]:\n",
    "        for f in range(5):\n",
    "            X_test=X[int(f*(len(X)-1)*0.20):int((f+1)*(len(X)-1)*0.20),:]\n",
    "            X_train=np.vstack((X[0:int(f*(len(X)-1)*0.20),:],X[int((f+1)*(len(X)-1)*0.20):,:]))\n",
    "            Y_test=Y[int(f*(len(Y)-1)*0.20):int((f+1)*(len(Y)-1)*0.20)]\n",
    "\n",
    "\n",
    "\n",
    "            acc_list=[]\n",
    "            acc=[]\n",
    "            pre=[]\n",
    "            rec=[]\n",
    "            cm=np.zeros(16*16).reshape(16,16)\n",
    "\n",
    "            for i in range(len(X_test)):\n",
    "                dict_ex={}\n",
    "                yi=int(Y_test[i])\n",
    "                \n",
    "                number=dataset.iloc[np.argsort(predict(X_test[i]))[:k]][\"Personality\"].to_numpy()\n",
    "\n",
    "\n",
    "                result=max(set(number),key=list(number).count  )      \n",
    "\n",
    "                if result==Y_test[i]:\n",
    "                    acc_list.append(True)\n",
    "                    cm[result,result]+=1\n",
    "                else:\n",
    "                    acc_list.append(False)\n",
    "                    \n",
    "                    cm[yi,result]+=1\n",
    "\n",
    "                print(\"Progress:%{} loop{}\".format(i*100//len(X_test),f),end=\"\\r\")\n",
    "\n",
    "\n",
    "                acc.append((acc_list.count(True)/len(acc_list)))\n",
    "\n",
    "                rec.append(cm[yi,yi]/int(np.sum(cm[:,yi])))\n",
    "\n",
    "                pre.append(cm[yi,yi]/int(np.sum(cm[yi,:])))\n",
    "\n",
    "        print(\"k: {} Accuracy %\".format(k),sum(acc)/len(acc)*100)\n",
    "        print(\"k: {} Precision %\".format(k),sum(pre)/len(pre)*100)\n",
    "        print(\"k: {} Recall %\".format(k),sum(rec)/len(rec)*100)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "     \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "826db43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1 Accuracy % 97.90771958220047\n",
      "k: 1 Precision % 97.89805453670454\n",
      "k: 1 Recall % 97.91757157775191\n",
      "k: 3 Accuracy % 99.04891309738714\n",
      "k: 3 Precision % 99.04986123436383\n",
      "k: 3 Recall % 99.05430368790002\n",
      "k: 5 Accuracy % 99.08026641196018\n",
      "k: 5 Precision % 99.07826078668968\n",
      "k: 5 Recall % 99.09074287720638\n",
      "k: 7 Accuracy % 99.07028347012759\n",
      "k: 7 Precision % 99.06894357418173\n",
      "k: 7 Recall % 99.07831481022382\n",
      "k: 9 Accuracy % 99.0993178821496\n",
      "k: 9 Precision % 99.09626321030154\n",
      "k: 9 Recall % 99.10960974172531\n"
     ]
    }
   ],
   "source": [
    "\n",
    "KNN_F_N()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c5aea",
   "metadata": {},
   "source": [
    "The best accuracy is in k=9 with normalization \n",
    "The best precision is in k=9 with normalization\n",
    "The best recall is in k=9 with normalization\n",
    "\n",
    "So we can understand from here best k value is 9 and best way to make precision is with feature normalization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
